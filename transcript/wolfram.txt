 
.....

okay well i'd like to welcome everybody to what i believe maybe the record breaker for the applied math colloquium over the history of m i t before i start let me mention that there are about four five seats right here if people sitting want to just grab those ... so it's a special pleasure to introduce this the well from doctor wolfram is graduate of of ... caltech we did is p h d in and then seventy nine at the age of twenty in theoretical physics any set still interested in science even after doing that ... so everybody here i think knows doctor wolfram so in the middle on introduction i did realize today that we had over applied mathematics we had at least one of the early copies a mathematica one doing the first few months of and the company's existence as i understand ... now we're certainly still users today so without further ado i've i've got a present for doctor wolfram don't even after you get a good from the from the from the mathematics department so without further ado let me introduce doctor wolfram who by the way is a local resident of a suburb of boston's of is very much one of our ... this one ... oh well those with ... now there's a light okay and how it works the ... i was going to set i think they're good the last twenty years of my life very much summarized by to these two big books and today and i'm going to talk about this one so ... it's huh-uh ... it's about twelve hundred pages long so that means that about a one hour talk i get spend an average of about three seconds on each page so i'm not going to get into tremendous depth but i hope i'll be able to communicate and these little bit of of of what's in it and a little bit a sort of the whole intellectual structure that i've spent the better part of the last twenty years building ... well back in the in the late nineteen seventies i was a young physicist mainly working on particle physics bottles of with a certain amount of work on cosmology and from that i got interested in the question of of how structures emerge in our universe from from galaxies on that and looking at that question i i quickly realized that it was actually an instance of a a much more general question which is sort of how does anything complicated get produced in nature well the lots of everyday examples snowflakes turbulent fluid flows forms of plants and animals lots of others well my first assumption was that with sort of all the sophisticated math that i'd knew from particle physics and so on i'd easily be able to figure out what was going on in this sort of ordinary everyday systems one i actually tried to do it though it didn't seem to work and gradually i started thinking that has a mighty sort of a fundamental problem with the whole approach to learn is taking ... well if one looks of history the idea reviews in math and mathematical equations to understand nature has been sort of a defining feature of the exact sciences for perhaps three hundred years and is certainly worked out extremely well for newton and friends of figuring out orbits of comets and for lots and lots of things since that but somehow when the behavior one's looking at is more complicated it just doesn't seem to work so well gradually what i began to think what's that that was actually why that never really been a good theory for complicated processes in in nature in physics some particularly in biology and so on i got to wondering about whether they might somehow be way to go sort of beyond the usual paradigm of using mathematical equations in in thinking about nature ... well that was around nineteen eighty one and it's so happened that that i might just spent time developing a big software system called s m p that was in some ways a forerunner of mathematica and of the core of s m p was 
.....

is to fairly long and complicated program so the specifically set up for particular costs but what i want to know about who really simple short programs say just chosen at random so what the programs like that do it's sort of the simplest possible computer experiment run the simplest programs see how they behave ... well back in nineteen eighty one item up with particular kinds of programs to try but they're actually been invented in different form before known a cellular automata they have quite a history here's how a simple one dimensional cellular automaton works so one starts with the row of cells each either black or white then a cellular automaton evolves down the page with the color of each cell on each step being determined by definite rule from the color cell and its neighbors on step before well in this particular case the rule is really simple it just says this cell would black whenever it or its neighbors were black on the row before and what happens is that we just get a simple uniform black pattern ... well we can use that icon at the bottom that to represent the rule the program we using so what happens if we change that rule of that well now instead of getting just a uniform black pattern we get a checkerboard so far none of this is time the surprised we using very simple rules what getting simple patterns out well okay let let's try to another rule ... it's the same setup as before but what's going on here and say we don't seem to be getting any kind of simple repeating pattern well let's run it a bit longer they get pretty intricate but we can see it's very regular it's just the self similar or fractal pattern just formed from nested pieces and one might think that if one has a simple rule and one starts from just a single black cell the mom would always have to get a pattern that's somehow very regular like this well least back in in nineteen eighty two that's what i assumed was true ... but one day i decided to try a a very systematic experiment and just to run every single one of the two hundred and fifty six possible 
.....

complicated structures running around because what what's going to happen well the only way to find out seems to be just as sort of keep running the system so we going to get more of those little structures or ... the structures going to collide with each other and i out of but what's going to happen well uh after two thousand seven hundred and eighty steps was finally get the on so and least in this case we basically just end up with one structure ... but it's amazing everything we get just starting from sort of one simple black cell and then following up a really simple rule ... well in the mid nineteen eighties i'd i'd studied a bunch of cellular automaton i'd seen these basic phenomena but i wasn't sure whether they were somehow specific to cellular automata or more general oh i have the practical problem is that there wasn't any easy way to set up all the sort of very different types of experiments that i'd have to do to find out in fact that was one of the main reasons i started building mathematica i wanted sort of once and for all to make a system that i could use to do all the computations and all the computer experiments i i'd ever want well for about five years the cost much and building the first version of mathematica and so on in our company pretty much consumed make but but finally in about nineteen ninety one i i decided i can start looking at my science questions again and it was the lake of what mean things that have taken me days to do before now took minutes was sort of easy to do all the experiments i've wanted a certain is a little like what it must've felt when telescopes or microscopes were first invented one could sort of just point them somewhere and almost immediately see oh uh whole world of new phenomena like you know microscopic creatures swimming around in drops a pond water or whatever well in the computational world one just pointed mathematica someone certainly one can see all this amazing stuff so the first question was just how special law cellular automata ... well i looked at lots of cellular automata often saw very complicated behavior what about programs with different setups like here's turing machine for example it's got 
.....

early twenty five hundred years ago the greeks looked for example prime numbers uh there's a fairly simple rule up fairly simple program for generating all the primes but the sequence of primes once generated looks remarkably irregular and complicated there's also fairly simple rule for generating the digits apply but once generated that sequence looks to us completely random actually there are lots of cases of this kind of thing with numbers i mean there's what happens if you just write out successive powers of three and base two it's kind of like a minimal version of a linear congruential random number generator already amazingly complicated you could also makers complicated sequences from simple integer occurrences ... if for example is the simplest primitive recursive function that has complex behavior ... well what about other systems based on numbers what about for example those favorite things from traditional mathematical science partial the financial equations does there continuous character make them work differently well the ones people usually study show only rather simple behavior but in doing and and automated search and the space of possible symbolic equations i ended up finding these creatures there just simple mom an impartial financial equations but even with very simple initial conditions they end up doing all sorts of complicated things well actually it's a little hard to tell exactly what they do i mean we use these p d e's to test our not ever improving sort of state of the art p d e solving capabilities of mathematica but with continuous systems there's always a problem that is you end up having to discretize them and without already more less knowing be on so it's hard to tell whether what you're seeing is something rate it's probably why among mathematicians numerical experiments can sometimes have something of a bad nine but in a discrete system like rule thirty then always seems like that and and the bits of the bits hmm one can tell the one seeing a real phenomenon and actually rule thirty is sort of so simple to set up there's no good reason i think the babylonians couldn't have done that i sometimes wonder 
.....

latent heat released and that inhibits more ice from solidifying nearby well so what's the simplest way to capture that fact what you just change the cellular automaton to say that ice gets added only if the number of neighboring cells the poor already ice is exactly want okay so what happens then well here's the on some ... and the soul stages that one sees and these look an awful lot like real snowflakes it it really seems like we've captured the basic mechanism that makes snowflakes have shapes they do and we get various predictions like that big snowflakes will have little holes in them from wow arms collided which and debate do okay but even though the pictures we have light look a lot like real snowflakes there are obviously details that are different the one thing one has to understand is that that always going to happen with a model but the whole point of a model is to capture certain essential features of a system and idealize away everything ounce and putting what one's interested in one may pick out different features to capture and so cellular automaton model is good for example if one's interested in the basic question of why snowflakes have complicated shapes well what the distribution of shapes in some snowflake population will be it's not so useful if one's tried on serve question like specifically how false teach arm will grows certain temperature ... and i say that there's actually a a sort of general confusion about models that often seems to surface when people first hear about cellular automata they'll say okay it's all very nice that cellular automata can reproduce what snowflakes do but of course real snowflakes aren't actually made from cellular automaton cells well the whole point so model is that it's suppose to be an abstract way of reproducing what a system does it's not supposed to be the system itself i mean one we have differential equations that describe how the earth moves around the sign we don't imagine that inside you throw all sorts of little mathematicas solving differential equations it's instead it's just the differential equations represent abstractly 
.....

system and successively excavating higher and i'll the digits hum-um and from the perspective of ordinary continuous mathematics there's some trickiness in accounted for where the randomness comes from there but looked at in terms of programs it's very clear that the randomness one gets out is just randomness that one put in in the detail patent of digits in initial conditions so can this ends up being an explanation that says effectively randomness comes from outside system one's looking at okay so is there any other possibility well it turns out that there is so just look at rule thirty ... here one doesn't have any randomness initially one just has a single black cell and one doesn't have any subsequent input from the outside but what happens is that the evolution of the system just intrinsically generates apparent randomness okay so what about fluid turbulence well so where does the randomness come from that well with the traditional differential equations way of modeling fluids it's very difficult to find out but one can make a simple cellular automaton model where it's considerably easier so remember that at the lowest level fluid just consists a bunch of molecules bouncing around to and actually we know the the details are two important because and and water and all sorts of other fluids with completely different microscopic structures so show the same continuum fluid behavior so knowing that you can try to sort of make a minimal model for the underlying molecules just have them on a discrete grid with discrete velocities and so on well if one does that one both gets a rather nice practical way to do some fluid mechanics but what else go can start addressing some fundamental questions and what one seems to find is that there's no need for randomness from the environment all randomness from initial conditions one could get randomness from intrinsic randomness generation from from something like rule thirty ... well okay so a lot if one's trying to make models of fluid turbulence is kind of important to know where the randomness and comes from and intrinsic randomness generation makes a least one immediate prediction it says that in a cat flea enough controlled experiment 
.....

complexity of course the complete genetic program for a typical organism is put in long and complicated for humans it happens to be about the same length is the source code for mathematica but ... it's increasingly clear that lots of the most obvious aspects of forms them patterns in biology or actually governed by rather small programs and looking at some of the kinds of regularities that one sees in biological systems that doesn't seem too surprising one one sees more complicated stuff traditional intuition tends to suggest that somehow it must have been difficult to get and with the usual natural selection picture there's sort of the idea that it must but the result of along and difficult process optimization or try to fit into some complicated ecological niche well i actually think that that's not where many of the most obvious examples of complexity in biology come from natural selection seems to be quite good of operating on some small numbers of smooth parameters lengthening one bone shortening another and so on but when there's more complexity involved it's very hard for natural selection operate well and instead what i think one ends up seeing is much more just the outcome and sort of typical randomly chosen genetic programs so let me give you an example there's some mollusk shells with pretty complicated pigmentation patterns on them well in the past one might of assumed that to get things as complicated as this must be difficult it's somehow it must be the result of a sophisticated biological optimization process ... but if you look at these patterns they look incredibly similar to patterns we get from cellular automata like rule thirty well and the actual shell the pattern is laid down by a line of pigment produce an cells on growing edge of the shell and it seems that what happens can be captured rather well by cellular automaton rule so why one rule and not another well if one looks of different species one sees all sorts of different patterns ... that's a neat thing is that there are definite classes of patterns that one sees that correspond remarkably well with 
.....

and we don't we don't is a picture for that ... and so traditional mathematical approaches of of obviously had lots of success and fundamental physics but still they haven't been able to give us a truly fundamental theory of physics and i suspect that the reason for that is that really one needs more primitives but just the ones from traditional mathematics but also the more general ones that one can have in programs and now we've seen that very simple programs can produce immensely rich complex behavior one can help wondering whether perhaps sort of all the amazing things we see in our universe couldn't just be the result of some particular simple program i mean that would be pretty excited have a little program that's sort of a precise ultimate model for our universe so that if one just runs that program long enough it'll reproduce every single thing that happens in our universe ... but okay so what might such a program be like well one thing that's kind of inevitable is that very few familiar features of our universe will immediately be visible in the program there just isn't wrong i mean it's a program is small there's just no way to fit in separate identifiable pieces the represent electrons oh gravity where even space of time in fact i think that if the program's going to be really small it's sort of has to have the very least possible structure already built in but i think for example the cellular automaton already has far too much structure built in in for example start a whole rigid array of cells laid out in space it also separates the notion of space from the notion of states of cells and i don't think what even needs that i mean in ordinary physics space is the kind of background on top of which matter and everything else exists but i think that an ultimate model one needs only space one doesn't need any other basic concepts ... well okay so given that what might space be well we normally think of space is just be sort of something that is not something that has any kind of underlying structure but i think it's a little like what happens with floats our everyday experience is that something like water is a continuous 
.....

formulation of physics space and time always very much the same kind of thing just different variables corresponding to different dimensions but when we look programs they seem much more different i mean in a cellular automaton for example one moves in space by going from one cell to another but one moves in time by actually applying cellular automaton rule okay so so can space and time really be that different well it's all rather tricky but i think of the lowest level they all it's definitely not like in a cellular automaton though because in a cellular automaton there's a kind of at a global clock with every cell getting updated in college every tick well it's hard to imagine how such a global clock could exist in our universe so what might actually be going on ... well there's something that at first seems crazy how about if the universe works like a turing machine or what i call a mobile automaton word each step there's only one cell what's ever getting updated there's no problem with synchronization here because there's only one place where nothing happens of time but how can this possibly to write them enough rule we normally have the impression that everything the universe is sort of going through time to get i certainly don't have the impression that what's happening for example is that sort of first time getting updated then you're getting updated and so on ... but the point is how would i actually know ... because until i'm updated icon tell whether you've been updated or not well if one follows this all the way through one realizes that all we can ever actually know about and the and is a kind of causal network of what event influences what other of that so here's an example of how one can go from an underlying sequence of updates in this case in a mobile automaton tour causal network an important thing here is that even though the updates only affect one cell of the time the final causal network corresponds something kind of uniform in space time ... okay so so how my time work 
.....

standard theory for gravity one needs to start off by talking about curvature in space well here's an example of a network that corresponds to ordinary flat two dimensional space what halves if we change the connection sort of we make some heptagons or some pentagons into those hexagons the answer is that we get a space that bulges out or bulges eng so remember that in two dimensions the number of nodes we get by going out addison sort is suppose to grow like r squared well in ordinary flat space it's exactly r squared but i cut space there's a correction to and turns out that that's proportional to the so called ritchie scalar curvature well that's already kind of interesting because the ritchie scalar curvature is exactly a thing that appears in the einstein equations with specify the structure of space time in general relativity it well story is quite complicated reaction you to look a coach an unjust in space but in space time defined by causal networks but it then turns out the the growth rates of volumes of space time cones related to the ritchie tensor and then what's certain microscopic randomness in other conditions it looks like one can derive conditions on the ritchie tensor and guess what they to seem to be exactly the einstein equations so there are many issues and camp outs but it is so exciting it's it seems like from almost nothing one's been able to derive a major feature of our universe namely general relativity and gravity ... okay so another major thing in our universe is particles like electrons and photons and so on well remember that all we have in the universe is specs so how can we get particles well sears i can work something like a cellular automaton here's a particular cellular automaton happens to doubt friend rule one ten we start off and random initial colors of cells but we see is that the system quickly organizes itself and two of you persistent localized structures and these localized structures act just like particles there a couple of collisions between them for example two particles come in office certain amount of attraction all but particles come out it almost looks like sort 
.....

mathematica but i think and the end it's going to work and and it's going to be pretty exciting ... well okay i want to come back now to be sort of original discovery they're really launched everything i've been talking about the discovery that even simple programs like rule thirty can produce immensely complex behavior ... so why does that happen what's the fundamental reason well so on so that one needs to set up as someone new conceptual framework and the basis of that is to think about sort of all processes as computations the initial conditions for a system of the inputs and the behavior that's generated as the output well sometimes the computations are ones that we kind of immediately know the point off like here's a cellular automaton that computes the square of any number you've given a block of n cells and it generates a block of n squared cells here's a cellular automaton the generates the primes but actually any cellular automaton can be thought of as doing computation just doesn't necessarily a computation that we kind of know the point solve beforehand ... okay so we have all sorts of systems made all sorts of computations but out all these computations compare i mean we might have thought that every different system would always do a completely different kind of computation so that if one wanted do addition one would buy an adding machine but wanted do exponentiation normal by an exponentiation machine but the remarkable idea that's now so about seventy years old is that no that's not necessary instead it's possible to make a universal machine that can do any computation it is just fed the right input of course that's been a pretty important idea because as the idea that makes software possible and really it's the idea that launched the whole computer revolution strangely enough though it's not an idea that's in the poll asked how much effect on the foundations of natural science one of the things that comes out of what i've done is that actually i think it has some very important implications that'd 
.....

corresponds to simple computation but what the principle of computational equivalence says is the one we don't see those kinds of regularities we're almost always seeing a process that in a sense maximally computationally sophisticated now first that's pretty surprising because we might of thought but the sophistication of the computations that get done would depend on the sophistication of the rules that got put n but the principle of computational equivalence says of dust and that immediately gives us a prediction it says that even though their rules are extremely simple systems like rule thirty should be computation universal ... well normally we'd imagine that to achieve something as sophisticated as computation universality we'd somehow need sophisticated underlying rules and certainly the computers we have the universal have c p u chips with millions of gates and and so on but prince will of computational equivalence says you don't need all of that it says that even cellular automata with very simple rules should be universal ... here's one of them this is rule one ten i showed it earlier it's got some if a really simple rule but as you can see it does some fairly complicated things it's got all these structures running around that seem like they might be doing logic operations of something become one really is some bold on to get something one can see is universal well one day i think it's going to possible to automate most to the process of figuring that out i didn't have that automation so i ended up getting a as human assistant of mine to do it instead but ah after a lot of painstaking work one indeed gets the results but rule one ten is universal ... well that's just what the principle of computational equivalence said should be true but it's really a remarkable thing was it means that this little rule can effect produce behavior that's as complex as any system one doesn't need anything like a whole computer c p u to do universal computation one just these this little rule ... and that has some very important consequences why comes to thinking about nature was it wouldn't expect to find whole computer c p u's just lying around in nature but we definitely can expect to 
.....

will be exactly computationally equivalent to the system they're observing and and that's then why your behavior of the system will inevitably seem to them complex ... well related consequence of a principle of computational equivalence is a an important phenomenon the michael computational irreducibility let's say you know the rules on the initial conditions for a system well then you can certainly work out what the system will do just by explicitly running it but the question is would you can somehow shortcut that process and if for example this work out a formula for what will happen in the system without ever explicitly having to trace each step if you can't the what it means is that you can figure out what the system will do with a lot less computational effort that takes the system itself and that kind of computational reducibility is that the core of most traditional theoretical science i mean if you want to work out were an idealized earth will be a million years from now you don't have to trace all its million orbits you just have to plug in number two formula and get out the results but the problem is what happens when the behavior is more complex if the system is repetitive or even nested it's easy to shortcut things what about a case like this though me there's certainly no obvious way to shortcut this and if i to think it's computationally irreducible there's essentially no way to work out what the system will do by any procedure that takes less computational effort than just running the system and seeing what happens ... to the traditional theoretical science there's sort of been an idealization made that the observer is an infinitely computationally powerful relative to the system they're observing but the point is that when there's complex behavior the principle of computational equivalence says instead of the system is just as computationally sophisticated as the observer and that's what leads to computational irreducibility and that's in a sense why traditional theoretical science hasn't been able to make more progress one one sees complexity there are always pockets of reducibility where one can make progress but there's always a core 
.....

although there's a way to arrange some complicated molecule in salt crystal below a certain temperature actually expect that but when the things that sort of seem so random that they just have to get tabulated and things like chemical tables it's the sign that there's computational irreducibility at work ... well there's another big place what i think computational irreducibility's very important and that's in the foundations of mathematics and may sound kind of obvious but it's really i think a deep observation about mathematics but it's often hard to do then it's based some per simple axioms i mean in fact quite year other ones for essentially all of current mathematics but even though these axioms a simple proofs of things like the four color theorem or fermat's last theorem a really long and it turns out the one can think about is just another case of the phenomenon of computational irreducibility let me show you a little bit about how that works and and here's an example of a simple proof in mathematics these are some axioms here in this case specifying equivalences in logic and this is a proof ... and starts from one expression the top then keeps on using the axioms and eventually proves the theorem that the expression of the top is equivalent of the one of the bottom ... well okay here's so it's kind of a minimal idealization of math one could imagine that the axioms just define transformations between strings so the axioms that the bottom here here proofs of a few theorems so how long the the proofs need to be ... well here's a picture for three axiom systems show on the network of all possible transformations and always works every possible part through each network corresponds to the proof of some theorem well the point is that the shortest off from one particular string to another maybe really long and that means that the theorem that the strings are equivalent has only a really long proof ... well when people or thinking about formalizing mathematics a century ago they kind of assume that in any given axiom system it always eventually be possible to give a proof of whether a particular statement was true or false ... so is a big shock in nineteen thirty one when godel's 
.....

prided itself on somehow being very general so then why haven't rule thirty and rule one ten a rule the phenomena i found in simple programs showed up well i think part of the reason is that mathematics isn't really quite as general as advertised i mean to see what could be one can imagine just enumerating possible axiom systems and for example this shows what theorems a true for sequence of different axiom systems it's kind of like an ultimately desiccated form of mathematics the axioms go down left the theorems go across the top and there's a there's a black dot every time a particular theorem is true for a given axiom system ... so ... there's there's something special about the actual axiom systems that get used in mathematics that someone that makes undecidability less rampant well if one looks at axiom systems from textbooks they're usually pretty complicated like here's logic for instance it's been known for a hundred years that that the one doesn't need all those so operators and a single nand operator or sheffer stroke is enough but the obvious axiom system with that is still pretty complicated well from the intuition that i'd built up about simple programs i suspected but there should actually be a really simple axiom system for logic probably with just one axiom ... and so i to search for that and lo and behold i found that i can tell you that this is the very simplest possible axiom system for logic there's the proof by the white needless to say generated by computer ... well knowing this i can say that if one just enumerates axiom systems logic will be about the fifty thousand one the one reaches so what about all the other one's one most of them are perfectly reasonable axiom systems too they just don't happen to be known fields of mathematics and actually i think mathematics says it's developed is been a sense tremendously constrained at some level it's really still pretty much just the direct various direct generalizations of the arithmetic and geometry that got studied in ancient babylon well if one starts looking at simple programs and just doing experiments one immediately sees a much wider world sort of this huge generalization of what mathematics has beans so fall ... so let me let me turn out a somewhat different topic just for from moment oh sort of talk about what the principle of computational equivalence says about sort of a a big question kind of our place in the in the universe it's it's it's always been natural for us to think that that we as humans up a very special but the history of science keeps on showing us ways in which we're not i mean for example four hundred years ago we found out that out our earth isn't of the special place in the universe a century and a half ago we found out that there wasn't anything special about the origin of species well every time we lose something in specialness science gets more general because it can drop another sort of footnote that says except in the case of humans but right now we still often think that we're special in our level of complexity are computational ability one of the big statements the principle of computational equivalence makes is that that isn't right it says that there are lots of simple abstract systems and systems in nature that are exactly equivalent in terms of their computational sophistication well one sometimes as that impression anyway for example or once is something like know the weather has a mind of itself well the principle of computational equivalence now says that yes fluid turbulence in the atmosphere will correspond as sophisticated computation is n a thing we do so was sort of not special at y ... one of things this as a consequence for the search for extraterrestrial intelligence is sort of been an idea that if we saw a signal was produced by sophisticated computation than there'd be no choice but to conclude that came from sophisticated extraterrestrial intelligence some sort of extraterrestrial civilization well principle of computational equivalence is no it's actually easier to do sophisticated computations and lots of things in nature do them it doesn't take our whole biological development in civilization to manager it it's by the way sort of why it's so hard to distinguish random radio noise from some kind of intelligent compressed encrypted signal well so where's that leave us sort of interest to think about of how we interact with the ultimate limits of of technology no i don't have any doubt that the be a time potentially quite soon one'll be possible sort of capture all the important features of human thinking in some piece of solid state electronics and know about things get more and more efficient until everything is on an atomic scale some sort of our processes of human thinking and just implemented by electrons whizzing around in lumps of something well of course there are electrons whizzing around in all sorts of complicated patterns in ordinary pieces of rock too and what the principle of computational equivalence tells us is that we can't expect the patterns made by the ones that represent human thinking to be ultimately any more sophisticated than those that occur naturally in something like a rock there are sort of isn't any abstract essence of human intelligence that one can identify what of course is still special about us is is all our details or history in a sense of the principle of computational equivalence that shows us that that history can really add up to something because if everything was computationally reducible in a sense nothing could be achieved by history we always be able to get to the same endpoint without a lot half ... it's sort of interesting what the principle of computational equivalence ends up saying it kind of encapsulates both the great strength on the great weakness of science but is on one hand it says that sort of all the wonders of our universe and be captured by simple rules it also says that there's ultimately no way to know the consequences of these rules except in effect just to watch and see how they unfold ... well it's remarkable to me what what's grown from those little computer experiments i did in the early nineteen eighties is about excited ... you know i started actually biting my book and in nineteen ninety one i i thought it would not take terribly long but i kept on looking at different areas and just finding all this wonderful 
.....

title of the book says sort of a new kind of science there really three threads that are emerging first a newer basic science by think we'll one day be like a physics or chemistry or mathematics but concerned with understanding sort of what's out there in the computational world it's kind of pure n k s and k s being the acronym for the title of the book but with sort of a a grounding in pure n k s one and star to do applications to take n k s results in math earns and use them and lots of areas in science and technology and elsewhere what's now one has lots of sort of new raw material for making models of things including perhaps our whole universe but also lots of new directions for technology because now we have all these new mechanisms not just sort of two years and we'll some things but things like rule thirty two that give us for example new ways to approach constructing algorithms what doing nanotechnology ... there's also kind of a like a a third thread so that n k s is sort of a conceptual direction understanding more about of the fundamental character of science and mathematics and about the place we have in our universe a sense giving a new framework for thinking about things in general whether in philosophy or in business again for example a new foundation for basic thread and education sort of it's alternative to mathematics there are many many possibilities so many things to be done many many things to be discovered a lot of sort of low hanging fruit to be picked ... no i i had a great time myself for to ten twenty year just sort of studying n k s myself but over the past year and a quarter it's been it's been exciting to see some any other people begin to get involved in in some ways and rather overwhelming and we've had nearly forty thousand you know messages about the book for example but is exciting it's kind of an intellectual analog of a startup company i suppose from managing companies for many years i'm i'm always interested sees of the people side of things and it's it's wonderful see many able people kind of getting in on the on the ground floor of the the n k s enterprise and leading position to 
.....

will be in april twenty second to twenty first and then waltham massachusetts and i know there are already at least fifty papers published a build on on n k s a bit actually i i got that number about six weeks ago so problem of the numbers is larger by now and i'm show like by the time of this n k s two thousand and four conference the be a lot more to hear about we're also going to do that the summer school again next year and also planning to plot sort of a more permanent n k s university presence and so on so that people who want to study n k s for sort of graduate school and and things can do that oh what i needed a number of other organizational things ... on the web there's also about to be a a serious n k s forum one thing i've been been working honest and write down sort of the best open problems them projects that i know in n k s it's turning out to be sort of at least one problem per page of the book and at this rate i i'm goods turn the the list of problems into into its own little book kind of it's kind of the complement of the n k s book the things that but aren't yes done ... well okay but in in terms of pure n k s what what should be organized that one big thing we've started to build up as a systematic sort of atlas of the computational world in annapolis of simple programs but you might show you later preliminary version of this you can find it but that was still wolfram dot com ... and the deepest kind of a mixture of computer generated material together with human commentary sort of explaining what's interesting why things work in a particular y in so on inside it's all of a big mathematica system them what it's ready for release it'll already be a terabyte or so of of date out is this kind of like a a bit like an astronomy database or inorganic chemistry database or a or the human genome database it's it's a combination of a map of what's out that and what seems interesting and there are lots of ways to imagine using the first one can try to classify and systematize to sort of do basic research but one can 
.....

well there's a lot to talk about i i wish i'd been able to tell you mall here but i've really only been able to sort of scratch the surface but i hope i've been able to communicate at least a little what's in that big book of mine and what at least i've been so excited about all these suits thank you very much ... that's for some questions and there are microphones and elect that the the police that of the microphones rebecca you've which which ... yeah ... the i a have a little pet rock and all ... who is of maximal computational complexity and i had the the following question i said ... i do a new kind of sciences but what is finance and iraq with replied well the u s x the experiments or is it kind of need some sort of record so you have physics chemistry which do with experiments and you have cosmology and biology to do with crime to read records and so my question to you is what is a new kind of science that is it it's try to do something different but so i mean because what try to distinguish sort of pure n k s from applied n k s pure n k s in terms of its sort of epistemological character something a bit like mathematics it's something well what one's interested in doing is sort of abstractly studying what's out there in the computational world what the simple programs abstractly do whether that's a worthwhile things do one then can mosque on the basis of either aesthetic considerations it being useful as of a thing to educate people about thinking about things one can ask about whether it can actually be applied to make models of things or to do technology in so and that sloan gets into sort of be applied n k s era and that one has to jot in part in the in exactly the same way that one's use to judging sciences um-hum sciences don't always make predictions that's a sort of physics based version of of what science does sciences can explain things or sciences can be things that have the word science and then then like computer science or whatever which which don't really have the same epistemological structure but term what what the way that you judge sort of applied n k s is doesn't make models of make predictions the useful does it allow you to create technology that's useful in so on and that that's i think i think it's sort of epistemological structure is quite similar to the epistemological structure of mathematics although its content is somewhat different ... it's ... and actually proven that rule thirty is kind of a and irreducible the same and you can prove that the halting problem of things up now i've not that i would love to ... i can tell you a certain amount that i now also in the case of rule one ten i know it's computation universal i don't know but for it if you also typical question you might not be if you look at a particular bit someone down is that effect of this formula for working out what this will be okay so you're asking what's the what's n that somehow alaskan but yes that's right because there is a form money you can so so for example one thing you can certainly do if you if you use and s is you could say let's apply funded a ... you 
cost of formula these of the minimal formulas for what happens you can see to get what's effectively an exponential increase in size of formula necessary describe what happens artists a successive number of steps this kind of sort of empirical evidence is one and several pieces of empirical evidence of what one seeing is something that sort of and irreducible computation i know that within the cost of disjunctive normal form expressions it is irreducible question is is it irreducible respects of all possible turing machine computations so let me give you know that give you there's other pieces of sort of circumstantial evidence about i haven't proved that to prove it be very interesting and i think quite hot of them sort of times develop some systematic tools that will allow one to sort of crunch through and make proofs like that but you know another perhaps interesting piece of circumstantial evidence you can ask well if we were just going to use of traditional mathematical formulas how would we ... let's say we have a one of some pattern like this nested pattern there's a there's a simple formula tells you whether bit will be whether a cell be black or white it's just you take the binomial coefficient of the x position and y position and you take it mod two and that tells whether you bit will be black or white so the fact about the this this kind of nested pattern gets described by binomial coefficients this like a more complicated nested pattern turns out it can only be described by gegenbauer functions which is somewhat more more rarified mathematical functions if you now ask what would you need to describe rule thirty you you could kind of see quite put the don't know rapidly ascending out of the domain of sort of classified mathematical functions that's another sort of pieces of evidence that you see computational irreducibility that you're not saying that the that the evolution of rule thirty does not correspond to something that can sort of be captured by some existing known mathematical function and i i could go on talk about it's it's out of ten the book talks about a bunch of sort of pieces of evidence for computational irreducibility 
.....

historian science that predict since the renaissance predictability and defined well here today as sort of science follows karl popper's ideas about scientific about the foundation which lies exact a computer science will use a computer scientist science that's just the poor and misuse of language no ... because i is about is that the the but the the the enough starting that this notion of predictability mathematics also does not have a notion of predictability motive biology really biology doesn't have theory particularly except perhaps for but natural selection which is not doesn't have the same come predictive status thing but there's copper signed the result in chemistry yeah it's well i think that the the so so to try and try and address this this issue of you know yes so the main thing that i've tried to do is to make sort of new raw material for making science so something with more the character of something like mathematics studying simple programs as raw material for for example making models in science now even going to the the much more controversial a messy thing of taking this nice pure abstract stuff and tried actually find how does match up what we actually see in the natural world and you could you know study your you know that that you know the growth of snowflakes and you can ask how well does this particular extremely simple model match what actually happens in real snowflakes and the answer is is someone like judge models is how much do you put in versus how much do you get out this does very well in that respect to put very little in yet you get lost out you can ask the same thing for models of leaf growth things like that if i write about fundamental physics the most spectacular example this will be that one will find a small model that actually represents or physics but these are things that in a sense the the core of sort of pure n k s is not really related to this question i mean it's it's a sort of pure investigation as you side the sense of sort of a combinatorial investigation of what's out there in the computational 
